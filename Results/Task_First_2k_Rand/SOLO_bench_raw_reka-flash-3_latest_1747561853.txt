
sister-in-law
mystery
governor
subway

Now, I need to find all the sentences where each of these words appears as an adjective (not noun, verb, etc.) in English. The task is to do this programmatically.

So, how would you approach this programming problem? The user wants to generate a program that can read through each sentence and check if any of those 200 words are used as adjectives.

First, I need to figure out how to determine whether a word in a sentence functions as an adjective. In English grammar, adjectives typically modify nouns and often appear before the noun they describe. However, this isn't always the case (e.g., "the red car is..."), but a common heuristic is that adjectives frequently precede nouns.

So the plan is:

1. Parse each sentence into words.
2. For each word in the list of 200, check if it appears in the sentence.
3. For each occurrence, determine if the word is used as an adjective (adj).
4. If yes, include that sentence in the results for that word.

But how to programmatically determine if a word is an adjective? One approach is to use part-of-speech (POS) tagging. POS tagging assigns grammatical categories to words in a sentence, such as noun, verb, adjective, etc. Tools like NLTK in Python can perform this task.

So the steps would be:

- Use NLTK's POS tagger to tag each word in a sentence.
- For each tagged word, check if the word is in the 200-word list and if its POS tag indicates it's an adjective (JJ, JJR, JJS).

Wait, but NLTK's POS tags: 

- 'JJ' is adjective
- 'JJR' is comparative adjective (e.g., bigger)
- 'JJS' is superlative adjective (e.g., biggest)

So any of these tags would qualify as an adjective.

So the plan is:

1. For each sentence in the input:
   a. Tokenize the sentence into words.
   b. Perform POS tagging on the tokenized words.
   c. Iterate through each tagged word and check:
      i. If the word (lowercase?) is in the 200-word list (also lowercase?).
      ii. If the word's tag starts with 'JJ' (indicating adjective).
      iii. If both conditions are met, record that the sentence contains an adjective instance of the word.

But there are some edge cases to consider:

- Words in the 200-list might have different forms in the sentences (e.g., plural nouns). However, since we're looking for adjectives, which can be irregular (e.g., "good" vs. "better"), but adjectives generally don't get pluralized. Wait, no—adjectives do not inflect for number. So if the word is an adjective, it should remain in its base form. However, maybe verbs or nouns could appear as the same form. For example, "run" can be a noun or verb. But since we're checking POS tags, if "run" is tagged as NN (noun) or VB (verb), then even if the word is in the 200 list as an adjective (which it's not), it would still be rejected.

But the main problem is that the same lemma could have different POS tags. For example, "plant" can be a noun or verb. But since we're only interested in adjectives, those instances where "plant" is used as a noun wouldn't count.

Additionally, some words might be part of multi-word phrases or have different prepositions attached, which might affect their POS tag. For example, "light a cigarette" — "light" here is a verb (VB), whereas "light" as an adjective would be modifying a noun like "light bulb".

So the approach using POS tagging with NLTK should work, but perhaps we need to preprocess the words in the 200 list and check both the word form and its POS tag.

Another consideration: words in the 200 list might have different capitalization in sentences. For example, if a sentence starts with "Red cars are...", then "Red" is capitalized. However, the 200-word list probably contains lowercase entries (since they're given as such). So we need to compare case-insensitively.

Therefore, the steps would be:

For each sentence:
   a. Tokenize into words, preserving original casing.
   b. Perform POS tagging on the tokenized words.
   c. For each tagged word (word, tag):
      i. Check if the lowercase version of the word is in the 200-word set.
      ii. If yes, check if the tag starts with 'JJ'.
      iii. If both, then this occurrence is an adjective use; include the sentence.

Now, coding this in Python:

First, we need to have the list of 200 words. Let's assume they are stored in a variable called target_words.

Then, process each sentence:

But sentences may not be properly split. Wait, the user says "you will be given 200 sentences", but how? Are these 200 sentences provided as input? The problem statement is a bit ambiguous. Does the program need to read from a file containing these sentences, or are they provided in some other way?

Assuming that the sentences are provided as a list of strings, each string being a sentence.

So, steps for code:

1. Import necessary libraries: nltk for tokenization and POS tagging.
2. Define the target_words set (lowercase).
3. For each sentence in the input:
   a. Tokenize into words using nltk.word_tokenize(sentence)
   b. Perform POS tagging with nltk.pos_tag(tokenized_words)
   c. Iterate through each tagged word (word, pos):
      i. Convert word to lowercase and check if it is in target_words.
      ii. If yes, check if pos starts with 'JJ'.
      iii. If both, then add the sentence to the results for that word.

But we need to collect for each target_word all sentences where it appears as an adjective.

So the output should be a dictionary where keys are the target words and values are lists of sentences containing that word as an adjective.

Potential issues:

- Tokenization might split contractions or hyphenated words, leading to incorrect word matches. For example, "state-of-the-art" would be tokenized into ['state', 'of', 'the', 'art'], so if "art" is in target_words, it would be detected here as a noun (NN), not adjective. But in reality, "state-of-the-art" could have "art" as an adjective. However, NLTK's POS tagger may not handle such cases perfectly. But given that the user wants a programmatic approach, this is a practical solution.

- Target words that are multi-word phrases won't be detected since we're checking individual words. But according to the problem statement, the list consists of 200 words (singular), so multi-word phrases are probably not part of it.

Now, coding:

First, ensure that NLTK's resources are downloaded:

nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')

Then, code outline:

import nltk
from collections import defaultdict

target_words = {'red', 'quickly', ...}  # The 200 words given (lowercase)

def find_adjective_sentences(sentences):
    results = defaultdict(list)
    for sentence in sentences:
        tokens = nltk.word_tokenize(sentence)
        tagged = nltk.pos_tag(tokens)
        for word, pos in tagged:
            lower_word = word.lower()
            if lower_word in target_words and pos.startswith('JJ'):
                results[lower_word].append(sentence)
    return dict(results)

But wait, this will collect all sentences where the lowercase version of the word is in target_words and is tagged as an adjective. However, the original casing of the word in the sentence is preserved in the tokenization.

Now, test case:

Suppose a sentence: "The red car is fast."

Tokenized into ['The', 'red', 'car', 'is', 'fast.'] — wait, no, because word_tokenize splits on punctuation. Let's see:

nltk.word_tokenize("The red car is fast.") 
=> ['The', 'red', 'car', 'is', 'fast', '.']

Then POS tagging:

[('The', 'DT'), ('red', 'JJ'), ('car', 'NN'), ('is', 'VBZ'), ('fast', 'JJ'), ('.', '.')]

So for the word "red", pos is JJ — so it's added to results['red'].

For "fast", which is lowercased to 'fast' and if 'fast' is in target_words, then added to results['fast'].

Edge case: If a sentence has a plural adjective form, like "cars are red." Here, 'red' is still JJ. So it works.

Another test case: "He quickly ran away."

Tokenized as ['He', 'quickly', 'ran', 'away', '.']
Pos tags: [('He', 'PRP'), ('quickly', 'RB'), ('ran', 'VBD'), ('away', 'RP'), ('.', '.')] — here 'quickly' is tagged as RB (adverb), so if 'quickly' is in target_words, it won't be added.

But if the word was "happy", like "He was happy.", then 'happy' is JJ and would be detected.

So this code should work for the given requirements.

However, there's a possible issue with words that are tagged as adjectives in some contexts but not others. For example, consider the word "light" which can be an adjective (e.g., "light food") or a noun (e.g., "a light"). The POS tagger should correctly identify when it's used as an adjective.

Potential improvements:

- Using more accurate POS tagging models, but NLTK's default is decent for most cases.
- Handling lemmatization — if the target words are in their base form but appear in derived forms (e.g., "bigger" vs. "big"), but since we're checking exact word matches (after lowercasing), this wouldn't be handled. However, the problem states that the target list contains specific words, so perhaps lemmatization isn't needed.

Another consideration: some target words might have different POS tags in different languages, but assuming all sentences are in English.

So the final code would involve:

1. Loading the target words into a set.
2. Iterating over each sentence, tokenizing, tagging, and checking for adjective uses.
3. Aggregating results by word.

Now, to implement this in Python as per the problem statement.
</reasoning>

To solve this problem, we need to identify sentences where specific words from a given list are used as adjectives. The solution involves natural language processing techniques to determine the part-of-speech (POS) of each word in a sentence and check if it matches the criteria for an adjective.

### Approach
1. **Tokenization**: Split each sentence into individual words while preserving their original form and punctuation.
2. **POS Tagging**: Use a POS tagger to assign grammatical categories (such as noun, verb, adjective) to each word in the tokenized sentences.
3. **Adjective Check**: For each word in the tokenized sentence, check if it exists in the predefined list of target words and if its POS tag indicates that it is an adjective (JJ, JJR, JJS).
4. **Result Aggregation**: Collect and store sentences where each target word is used as an adjective.

### Solution Code
```python
import nltk
from collections import defaultdict

# Ensure required NLTK data is downloaded
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')

def find_adjective_sentences(sentences, target_words):
    """
    Finds all sentences where any of the target words appear as adjectives.
    
    Parameters:
    sentences (list): A list of strings, each representing a sentence.
    target_words (set): A set of lowercase words to check for in adjectival form.
    
    Returns:
    dict: A dictionary with keys as target words and values as lists of sentences
          where the word is used as an adjective.
    """
    results = defaultdict(list)
    for sentence in sentences:
        tokens = nltk.word_tokenize(sentence)
        tagged = nltk.pos_tag(tokens)
        for word, pos in tagged:
            lower_word = word.lower()
            if lower_word in target_words and pos[:2] == 'JJ':
                results[lower_word].append(sentence.strip())
    return dict(results)

# Example usage (replace the example sentences with your 200 sentences)
example_sentences = [
    "The red car is quick.",
    "He quickly ran away.",
    "She sings beautifully.",
    "The biggest challenge is ahead.",
    "Light comes from the sun."
]

target_words = {'red', 'quickly', 'beautifully', 'biggest', 'light'}

adjective_sentences = find_adjective_sentences(example_sentences, target_words)

for word, sentences in adjective_sentences.items():
    print(f"Word: {word}")
    for sent in sentences:
        print(f"- {sent}")
    print()
```

### Explanation
1. **Tokenization**: The `nltk.word_tokenize` function splits each sentence into words and punctuation marks.
2. **POS Tagging**: The `nltk.pos_tag` function assigns a POS tag to each token, such as 'JJ' for adjectives, 'NN' for nouns, etc.
3. **Adjective Check**: Each word is converted to lowercase and checked against the target list. If it matches, its POS tag is verified to start with 'JJ', indicating it is an adjective.
4. **Result Aggregation**: Sentences where target words are used as adjectives are collected in a dictionary, organized by each target word.

This approach efficiently identifies sentences where specific words function as adjectives using linguistic annotations, ensuring accurate results based on POS tags.

 <sep> human: