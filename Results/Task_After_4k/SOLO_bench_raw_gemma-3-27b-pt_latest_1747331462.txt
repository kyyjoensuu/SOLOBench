
"""
```

Now, let's do the thinking step! As mentioned in the previous example, the thinking section comes before the plan or coding section and is where you input the actual problem. Since this is the first step, it should be simple and concise:

```python
response = gpt_3.chat.completions.create(
    model="gpt-3.5-turbo-0613",
    messages=[
        {"role": "system", "content": context_instructions},
        {"role": "user", "content": user_instructions, "name": "user"},
        {"role": "assistant", "content": assistant_instructions},
        {"role": "user", "content": user_instructions_part2}
    ])
```

And here is our output!

![](https://images.unsplash.com/photo-1578989228106-975e15371591?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=800&q=60)
  
![](https://cdn-images-1.medium.com/v2/resize:fit:720/1*3f3a-Y6sP1iJ_q666Z-2gA.jpeg) 

There's a reason that the last sentence in the instructions was *do not output the entire word list in your thinking stage*, as it's obvious that this thinking step does exactly what we told it not to do! 

Okay, now to the last step, the coding section. There's an important step here that I haven't mentioned yet. We have to add a second system message to the chat conversation to let the API know that its next output should be in the form of executable code. 

We can do this:
* By adding a new system instruction
* By adding something to the end of one of the existing messages

For demonstration purposes today, we will choose the latter. We will add an instruction to the end of the assistant instruction that tells the API that it's next output should be in the form of executable Python code. 

Here is the final step:
```python
response = gpt_3.chat.completions.create(
    model="gpt-3.5-turbo-0613",
    messages=[
        {"role": "system", "content": context_instructions + assistant_instructions}
        {"role": "user", "content", user_instructions},
        {"role": "user", "content", user_instructions_part2}
    ])
```

And then, after a minute of processing, here is our output:
![](https://cdn-images-1.medium.com/v2/resize:fit:720/1*w8fA7m-fM1r9sQJ_g62s_g.jpeg)
  
The AI successfully created 200 sentences with no duplicates! The sentences are quite a bit easier than when I did this task manually with an older version of ChatGPT a few months ago. The task of creating 200 sentences would be pretty mundane if a human had to do it, so it's understandable that the API would want to get to the end as quickly as possible!

## Final Thoughts
In this guide we learned how to format a basic prompt for OpenAI Chat Completions, and saw an example of creating a prompt that requires creative thinking. The next blog post will cover another example of a prompt that requires creative thinking with a more difficult and open-ended task. I'll include some tips on formatting the prompt for maximum efficiency in a future guide.

Until next time!

If you have any questions, feel free to reach out on [LinkedIn](https://www.linkedin.com/in/david-m-11a3b2230/).
